{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEWfCSRUldek"
   },
   "source": [
    "# Introducción\n",
    "Actualmente contamos con una cantidad ingente de información, de la cual gran parte se encuentra en forma de texto. Para las personas es fácil leerla y encontrar relaciones entre las palabras que conforman un texto, sin embargo para las computadoras es una tarea compleja. Debido a esto surgen áreas de las ciencias de la computación que se encargan de la extracción de información en texto mediante diversas técnicas. En este sentido, la información mutua es una técnica se puede aplicar en el descubrimiento de las asociaciones de\n",
    "palabras.\n",
    "\n",
    "El propósito de este documento es realizar el descubrimiento de asociaciones de palabras para los conjuntos de datos proporcionados utilizando la medida de información mutua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVleQIWkB37Y"
   },
   "source": [
    "# Desarrollo\n",
    "Para la solución de este problema se utilizó Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XIViOM9m_pHV",
    "outputId": "85b39129-beb6-4c71-c442-15c6a068e1a4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nofWSwoO_KTY"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import re\n",
    "import itertools\n",
    "from nltk.util import ngrams\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "V7x_cZAD_ujM",
    "outputId": "02c4161f-893d-437a-cd73-7938bbf0e608"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4r0MTtVBVuN"
   },
   "outputs": [],
   "source": [
    "es_stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiseN20NDmya"
   },
   "source": [
    "### Descripción de los datos\n",
    "Para realizar esta tarea se tienen 3 conjuntos de datos que están contienen tweets de México, España y Venezuela del mes de marzo de 2020, con 1000000, 1000000 y 300000 filas respectivamente. Cada conjunto está formado por 3 columnas: created_at, id y text. En este caso, la columna que nos interesa es text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8Cq5rOJ_zZI"
   },
   "outputs": [],
   "source": [
    "mx_tweets = pd.read_json(\"/content/drive/MyDrive/ProcesamientoInformacion/MX_1M.json\", encoding=\"utf-8\", lines = True)\n",
    "es_tweets = pd.read_json(\"/content/drive/MyDrive/ProcesamientoInformacion/ES_1M.json\", encoding=\"utf-8\", lines = True)\n",
    "vz_tweets = pd.read_json(\"/content/drive/MyDrive/ProcesamientoInformacion/VE_300K.json\", encoding=\"utf-8\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "EEFa5y_5HHnP",
    "outputId": "42a69d61-fe92-44d6-a1b0-7abd706dcdca"
   },
   "outputs": [],
   "source": [
    "mx_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7d8RjRlOstT"
   },
   "source": [
    "En la celda anterior podemos ver las primeras 10 filas del conjunto de datos de tweets de México."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqK4yxPnPtQM"
   },
   "source": [
    "### Implementación\n",
    "A continuación se describen las funciones usadas y se proporcionan ejemplos de su funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dnQroYq_z6U"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    no_urls = re.sub(r\"http\\S+\", \"\", text)\n",
    "    #remover @usuarios y #hashtags\n",
    "    without_users = re.sub('@[\\w]+','',no_urls)\n",
    "    without_users_and_hashtags = re.sub('#[\\w]+','',without_users)\n",
    "    #remover acentos\n",
    "    unaccented_string = unidecode.unidecode(without_users_and_hashtags)\n",
    "    #convertir a minuscula y remover signos de puntuacion\n",
    "    text_lower = unaccented_string.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    #limitar los characteres repetidos consecutivos\n",
    "    #obtenemos los tokens\n",
    "    text_tokens = word_tokenize(text_lower)\n",
    "    #filtramos las stopwords de los tokens obtenidos\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in es_stop_words]\n",
    "    tokens_without_dups = [limit_dups(token) for token in tokens_without_sw]\n",
    "    return tokens_without_dups\n",
    "\n",
    "def limit_dups(s, limit=2):\n",
    "    max_vs = (''.join(itertools.islice(g, limit)) for k, g in itertools.groupby(s))\n",
    "    components = ([s[:l + 1] for l in range(len(s))] for s in max_vs)\n",
    "    return [''.join(letters) for letters in itertools.product(*components)][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtCqJ_Yls4Tb"
   },
   "source": [
    "La función preprocess recibe una cadena de texto y se encarga de realizar el  preprocesamiento en el siguiente orden: remover urls, usuarios y hashtags, después se quitan los acentos, se convierte el texto a minúsculas y se remueven los signos de puntuación, se convierte el texto a tokens para posteriormente removerle las stop-words y finalmente se limitan los carácteres redundantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNA8FcHiV4fN"
   },
   "source": [
    "En la siguiente celda veremos el resultado de la función de preprocesamiento aplicada al texto: \"Felizzzzzzzz jueves!!! en Torre Reforma https://t.co/EV46yOUOEx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "H2ajpWiHVRFa",
    "outputId": "b9b0e4ad-f0d9-4ac2-94bc-2c8b28beaaf0"
   },
   "outputs": [],
   "source": [
    "preprocess(\"Felizzzzzzzz jueves!!! en Torre Reforma https://t.co/EV46yOUOEx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7Wx0CWubKU0"
   },
   "outputs": [],
   "source": [
    "def fill_dict(text_array):\n",
    "    my_dictionary = {}\n",
    "    for word in text_array:\n",
    "        for item in word:\n",
    "            if item in my_dictionary:\n",
    "                my_dictionary[item] = my_dictionary[item] + 1\n",
    "            else:\n",
    "                my_dictionary[item] = 1\n",
    "    return my_dictionary\n",
    "\n",
    "filter_dict = lambda my_dict, limit = 5: {k: v for k, v in my_dict.items() if v > limit}\n",
    "\n",
    "def calculate_mutual_information(data_dict, data_bigram_dict, limit = 50):\n",
    "  mx_mutual_information = {}\n",
    "  for item in data_bigram_dict:\n",
    "      mx_mutual_information[item] = mutual_information(item, item[0], item[1], data_bigram_dict, data_dict)\n",
    "  return sorted(mx_mutual_information.items(), key=lambda x:x[1], reverse=True)[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0je23Aqu37-h"
   },
   "source": [
    "La función fill_dict crea un diccionario a partir de un arreglo de strings usando cada palabra como llave. Si la llave ya está, se aumenta su cuenta, sino se le asigna un 1. Esta función se usa para contar la frecuencia de los tokens.\n",
    "\n",
    "La función filter_dict nos permite filtrar un diccionario por valor. Esta función se usa para filtrar los tokens que tengan una frecuencia menor a cierto valor. En este caso, 5 es un valor predeterminado.\n",
    "\n",
    "La función calculate_mutual_information obtiene las medidas de información mutua para todos los bigramas de un conjunto. Devuelve, de forma predeterminada, los 50 primeros ordenados según su índice de información mutua de mayor a menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pDtCOkBbGWM"
   },
   "outputs": [],
   "source": [
    "def mutual_information(xy, x, y, data1, data2):\n",
    "    pxy = data1[xy]/len(data2)\n",
    "    px = data2[x]/len(data2)\n",
    "    py = data2[y]/len(data2)\n",
    "    return math.log2(pxy/((px)*(py)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYLfCFG87Uk7"
   },
   "source": [
    "La función mutual_information nos permite calcular la información mutua de acuerdo a la siguiente fórmula: $I\\left ( x_{i};y_{i} \\right ) = \\log_2{\\frac{p\\left ( x_{i},y_{i} \\right )}{p\\left (  x_{i}\\right) p\\left (  y_{i}\\right)}}$, donde $p\\left(x_{i}\\right)$ y $p\\left(y_{i}\\right)$ se obtienen de las frecuencias relativas de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LF9gSnO-b0ci"
   },
   "outputs": [],
   "source": [
    "mx_tweets['processed_text']= mx_tweets['text'].map(preprocess)\n",
    "es_tweets['processed_text']= es_tweets['text'].map(preprocess)\n",
    "vz_tweets['processed_text']= vz_tweets['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6DYAZmC9-uA"
   },
   "source": [
    "### Resultados\n",
    "Primero aplicamos el preprocesamiento al campo text de cada uno de los conjuntos y lo asignamos a una nueva columna llamada processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH_myVWVb3Zn"
   },
   "outputs": [],
   "source": [
    "mx_tweets[\"bigrams\"] = mx_tweets[\"processed_text\"].apply(lambda x: list(ngrams(x, 2)))\n",
    "es_tweets[\"bigrams\"] = es_tweets[\"processed_text\"].apply(lambda x: list(ngrams(x, 2)))\n",
    "vz_tweets[\"bigrams\"] = vz_tweets[\"processed_text\"].apply(lambda x: list(ngrams(x, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QtM4pkT95ip"
   },
   "source": [
    "Luego obtenemos los bigramas a partir del texto procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMbtvwA5cBtF"
   },
   "outputs": [],
   "source": [
    "mx_dictionary = fill_dict(mx_tweets['processed_text'])\n",
    "es_dictionary = fill_dict(es_tweets['processed_text'])\n",
    "vz_dictionary = fill_dict(vz_tweets['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8ZWSX4hb7od"
   },
   "outputs": [],
   "source": [
    "mx_bigram_dictionary = fill_dict(mx_tweets['bigrams'])\n",
    "es_bigram_dictionary = fill_dict(es_tweets['bigrams'])\n",
    "vz_bigram_dictionary = fill_dict(vz_tweets['bigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8pHXNWo_WHS"
   },
   "source": [
    "Después se llenan los diccionarios con las frecuencias de las palabras y bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOBUT6anfHIW"
   },
   "outputs": [],
   "source": [
    "mx_dictionary_freq_filtered = filter_dict(mx_dictionary)\n",
    "es_dictionary_freq_filtered = filter_dict(es_dictionary)\n",
    "vz_dictionary_freq_filtered = filter_dict(vz_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgHgLgvJhhWD"
   },
   "outputs": [],
   "source": [
    "mx_bigrams_dictionary_freq_filtered = filter_dict(mx_bigram_dictionary)\n",
    "es_bigrams_dictionary_freq_filtered = filter_dict(es_bigram_dictionary)\n",
    "vz_bigrams_dictionary_freq_filtered = filter_dict(vz_bigram_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB1Yl2te_fQC"
   },
   "source": [
    "Posteriormente se filtran los diccionarios para quedarnos solo con aquellos que tengan una frecuencia mayor a 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o73eHo9mAswM"
   },
   "source": [
    "Finalmente, llamamos a la función que calcula la información mutua para los datos de cada conjunto y obtenemos una lista de tuplas de las 50 asociaciones más importantes junto a su índice de información mutua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XvavnJYahvND",
    "outputId": "913fb449-0630-4c83-baa6-662f768334ca"
   },
   "outputs": [],
   "source": [
    "\n",
    "mx_mutual_information = calculate_mutual_information(mx_dictionary_freq_filtered, mx_bigrams_dictionary_freq_filtered)\n",
    "mx_mutual_information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfUUWKSjbfkk"
   },
   "source": [
    "La lista anterior es la lista de las 50 asociaciones más frecuentes para el conjunto de datos de México. Podemos hallar asociaciones como Duane Cochran, prismas basálticos, Lindsay Lohan o Hakuna Matata, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "d8LNVT4E4UlM",
    "outputId": "fce18007-804b-4a25-d369-a0558474fffe"
   },
   "outputs": [],
   "source": [
    "\n",
    "es_mutual_information = calculate_mutual_information(es_dictionary_freq_filtered, es_bigrams_dictionary_freq_filtered)\n",
    "es_mutual_information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9Wd_f90cmge"
   },
   "source": [
    "La lista anterior es la lista de las 50 asociaciones más frecuentes para el conjunto de datos de España. Podemos encontrar asociaciones como Hugh Jackman, Greys Anatomy, Childish Gambino, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LIQ00S5T4d9c",
    "outputId": "b67481b4-cc7c-4ab4-def9-fb6bc5009f08"
   },
   "outputs": [],
   "source": [
    "\n",
    "vz_mutual_information = calculate_mutual_information(vz_dictionary_freq_filtered, vz_bigrams_dictionary_freq_filtered)\n",
    "vz_mutual_information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hfJATQ0cpon"
   },
   "source": [
    "La lista anterior es la lista de las 50 asociaciones más frecuentes para el conjunto de datos de Venezuela. Podemos hallar asociaciones como Peaky Blinders, hipertensa diabética, vivito coleando, feng shui, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzzTCFE4hSXC"
   },
   "source": [
    "Como último experimento, filtramos los tokens y bigramas que tengan una frecuencia mayor a 100 y nuevamente calculamos el índice de información mutua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "OlN9rzmoeO4G",
    "outputId": "32226147-3d1d-43de-bc98-c6569543f264"
   },
   "outputs": [],
   "source": [
    "mx_dictionary_freq_filtered_100 = filter_dict(mx_dictionary, 100)\n",
    "mx_bigrams_dictionary_freq_filtered_100 = filter_dict(mx_bigram_dictionary, 100)\n",
    "mx_mutual_information_100 = calculate_mutual_information(mx_dictionary_freq_filtered_100, mx_bigrams_dictionary_freq_filtered_100)\n",
    "mx_mutual_information_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsizf668Nxsh"
   },
   "source": [
    "Es interesante ver que hay asociaciones como ('neumonia', 'atipica'), ('pronta', 'recuperacion'), ('cubre', 'bocas'), ('gel', 'antibacterial'). Cabe destacar que en marzo de 2020 se declaró que (COVID-19) se podía caracterizar como una pandemia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A81xZ2ZhAPr-"
   },
   "source": [
    "# Conclusiones\n",
    "La medida de información mutua es muy útil para hallar asociaciones entre palabras en un texto. Sin embargo, su cálculo y las asociaciones que encontremos estarán directamente relacionadas con el preprocesamiento que le apliquemos al texto. Por otra parte, debe reconocerse su importancia es otras áreas como procesamiento de lenguaje natural o recuperación de información."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
